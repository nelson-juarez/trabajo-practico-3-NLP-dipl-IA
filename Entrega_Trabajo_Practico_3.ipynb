{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f58a224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 57.3 MB/s  0:00:00\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea6e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from textblob import TextBlob\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597c4898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1600000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                          date     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura archivo training\n",
    "path_train = \"./Training_data/Training_data.csv\"\n",
    "df_train = pd.read_csv(path_train, encoding='latin-1', header=None)\n",
    "df_train.columns = ['polarity','id','date','query','user','text']\n",
    "\n",
    "# df_neg = df_train[df_train[\"polarity\"] == 0]\n",
    "# df_pos = df_train[df_train[\"polarity\"] == 4]\n",
    "\n",
    "# # Samplear 100k de cada clase - Solo para el desarrollo\n",
    "# df_neg_sample = df_neg.sample(100000, random_state=42,replace=True)\n",
    "# df_pos_sample = df_pos.sample(100000, random_state=42,replace=True)\n",
    "# df_train = pd.concat([df_neg_sample, df_pos_sample]).sample(frac=1, random_state=42)\n",
    "\n",
    "# Lectura archivo test\n",
    "path_validation = \"./Training_data/Test_data_manual.csv\"\n",
    "df_test = pd.read_csv(path_validation, encoding='latin-1', header=None)\n",
    "df_test.columns = ['polarity','id','date','query','user','text']\n",
    "\n",
    "print('Shape:', df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fb3c2",
   "metadata": {},
   "source": [
    "### Limpieza y preprocesamiento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de01919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date_parsed</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>2009-04-06 22:19:45</td>\n",
       "      <td>awww s bummer shoulda get david carr day d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>2009-04-06 22:19:49</td>\n",
       "      <td>upset not update facebook texte cry result sch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                          date     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "\n",
       "          date_parsed                                         text_clean  \n",
       "0 2009-04-06 22:19:45         awww s bummer shoulda get david carr day d  \n",
       "1 2009-04-06 22:19:49  upset not update facebook texte cry result sch...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Funci√≥n para parsear la fecha\n",
    "def parse_date(s):\n",
    "    if not isinstance(s, str):\n",
    "        return pd.NaT\n",
    "    \n",
    "    s_clean = re.sub(r'\\b[A-Z]{2,4}\\b', '', s).strip()\n",
    "    \n",
    "    try:\n",
    "        dt = pd.to_datetime(s_clean, errors='coerce')\n",
    "        return dt\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df_train['date_parsed'] = df_train['date'].apply(parse_date)\n",
    "df_test['date_parsed']  = df_test['date'].apply(parse_date)\n",
    "\n",
    "# Aplico limpieza de datos para quitar urls, menciones a otros usuarios, hashtags, n√∫meros, puntuaciones y m√∫ltiples espacios.\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    doc = nlp(text)\n",
    "    return  ' '.join([token.lemma_ for token in doc if not token.is_stop])\n",
    "    \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df_train['text_clean'] = df_train['text'].apply(clean_text)\n",
    "df_test['text_clean'] = df_test['text'].apply(clean_text)\n",
    "\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fa2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()\n",
    "df_train = df_train[['text_clean', 'polarity']]\n",
    "X = df_train['text_clean']  \n",
    "y = df_train['polarity'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7622e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "0    50.0\n",
       "4    50.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5c1127",
   "metadata": {},
   "source": [
    "### Conclusiones:\n",
    "Se realiz√≥ una limpieza de datos para evitar tener ruido en el texto y evitar generar tokens que no sean relevantes, se cre√≥ una nueva columna \"text_clean\" con esta limpieza y lo mismo para la columna \"date\" creando la columna \"date_parsed\" para mantener una fecha m√°s simple y amigable.\n",
    "\n",
    "Se realiz√≥ un diagrama de distribuci√≥n para visualizar el balanceo de polarity.\n",
    "\n",
    "Se observa una distribuci√≥n equilibrada entre comentarios negativos y positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ac825",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0e61dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   text_clean  1600000 non-null  object\n",
      " 1   polarity    1600000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.info())\n",
    "\n",
    "#Diagrama de distribuci√≥n de polarity\n",
    "sns.countplot(x=df_train['polarity'])\n",
    "plt.title(\"Distribuci√≥n de polaridad\")\n",
    "plt.xlabel(\"Polarity (0 = Negativo, 2 = Neutral, 4 = Positivo)\")\n",
    "plt.ylabel(\"Cantidad de tweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424ee23",
   "metadata": {},
   "source": [
    "## Representaci√≥n vectorial\n",
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(\n",
    "    max_features=100000, \n",
    "    ngram_range=(1, 2), \n",
    "    min_df=5,\n",
    "    stop_words='english'            \n",
    ")\n",
    "\n",
    "X_train_tfidf = tf_idf.fit_transform(df_train['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0de8d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Top 15 palabras para clase 0 (Negativo)\n",
      "   T√©rmino  Importancia_TFIDF\n",
      "0     work           0.014601\n",
      "1     miss           0.014102\n",
      "2     want           0.010709\n",
      "3      day           0.010473\n",
      "4     feel           0.010054\n",
      "5     like           0.009070\n",
      "6    today           0.008445\n",
      "7      sad           0.008403\n",
      "8     wish           0.008356\n",
      "9    think           0.007794\n",
      "10    know           0.007514\n",
      "11     bad           0.007362\n",
      "12   sorry           0.007028\n",
      "13    time           0.007005\n",
      "14    good           0.006828\n",
      "\n",
      "üîπ Top 15 palabras para clase 4 (Positivo)\n",
      "    T√©rmino  Importancia_TFIDF\n",
      "0     thank           0.017756\n",
      "1      good           0.016910\n",
      "2      love           0.013539\n",
      "3       day           0.010949\n",
      "4       lol           0.008826\n",
      "5      like           0.008701\n",
      "6      time           0.007708\n",
      "7      know           0.007646\n",
      "8     today           0.006811\n",
      "9     great           0.006777\n",
      "10      new           0.006671\n",
      "11  morning           0.006589\n",
      "12     work           0.006565\n",
      "13    think           0.006554\n",
      "14    watch           0.006290\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top_tfidf_words_per_class(vectorizer, X, y, label, n=15):\n",
    "    \"\"\"\n",
    "    Obtiene los top-n t√©rminos TF-IDF m√°s importantes para una clase espec√≠fica.\n",
    "    \n",
    "    vectorizer : TfidfVectorizer ya entrenado\n",
    "    X          : Serie de textos originales (X_train)\n",
    "    y          : Serie de labels (0/4)\n",
    "    \"\"\"\n",
    "\n",
    "    corpus = X[y == label]    \n",
    "    X_tfidf = vectorizer.transform(corpus)\n",
    "    tfidf_means = np.asarray(X_tfidf.mean(axis=0)).ravel()\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    top_idx = tfidf_means.argsort()[::-1][:n]\n",
    "    top_terms = [(terms[i], tfidf_means[i]) for i in top_idx]\n",
    "\n",
    "    return pd.DataFrame(top_terms, columns=[\"T√©rmino\", \"Importancia_TFIDF\"])\n",
    "\n",
    "df_top_words = df_train.sample(n=100000, random_state=42)\n",
    "print(\"\\nüîπ Top 15 palabras para clase 0 (Negativo)\")\n",
    "top_neg = top_tfidf_words_per_class(tf_idf, df_top_words['text_clean'], df_top_words['polarity'], label=0, n=15)\n",
    "print(top_neg)\n",
    "\n",
    "print(\"\\nüîπ Top 15 palabras para clase 4 (Positivo)\")\n",
    "top_pos = top_tfidf_words_per_class(tf_idf, df_top_words['text_clean'], df_top_words['polarity'], label=4, n=15)\n",
    "print(top_pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61099220",
   "metadata": {},
   "source": [
    "### Conclusi√≥n:\n",
    "\n",
    "Para los datos ya limpios y libre de caracteres especiales se utiliz√≥ \"TF-IDF\" para determinar frecuencia de aparici√≥n de palabras y de esta forma qudarme con aquellas palabras que sean m√°s representativas. En este caso se us√≥ N-Gramas de 1 y 2 para analizar expresiones que pueden no considerarse o ser representativas de forma individual.\n",
    "\n",
    "Se realiz√≥ un top 15 para las clases de Negativos y Positivos, para el primer caso se observa que palabras como \"miss\" o \"work\" son m√°s frecuentes y para el caso de Positivos tenemos palabras como \"good\" o \"thank\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc574b5",
   "metadata": {},
   "source": [
    "## Regresi√≥n log√≠stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d7910d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1120000, 100000), (1120000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b868c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78    560000\n",
      "           4       0.77      0.81      0.79    560000\n",
      "\n",
      "    accuracy                           0.79   1120000\n",
      "   macro avg       0.79      0.79      0.79   1120000\n",
      "weighted avg       0.79      0.79      0.79   1120000\n",
      "\n",
      "------------------------------------------------------\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76    240000\n",
      "           4       0.76      0.80      0.78    240000\n",
      "\n",
      "    accuracy                           0.77    480000\n",
      "   macro avg       0.77      0.77      0.77    480000\n",
      "weighted avg       0.77      0.77      0.77    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplico el modelo de regresi√≥n log√≠stica\n",
    "mod_reg_log = LogisticRegression(random_state=1, max_iter=1000)\n",
    "mod_reg_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = mod_reg_log.predict(X_train)\n",
    "print(\"Train report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"------------------------------------------------------\")\n",
    "y_pred_test = mod_reg_log.predict(X_test)\n",
    "print(\"Test report:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc52279",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "El modelo de Regresi√≥n Log√≠stica mostr√≥ un rendimiento estable y consistente tanto en entrenamiento como en prueba, indicando una buena capacidad de generalizaci√≥n. En el conjunto de entrenamiento obtuvo una accuracy del 79%, mientras que en el conjunto de prueba alcanz√≥ un 77%, lo que representa una ca√≠da esperable.\n",
    "\n",
    "En cuanto al comportamiento por clase:\n",
    "\n",
    "* Clase 0 (Negativo):\n",
    "Presenta una mayor precisi√≥n en ambas particiones, lo cual indica que el modelo es relativamente conservador al identificar tweets negativos (cuando predice negativo, suele acertar). Sin embargo, su recall es ligeramente menor, lo que implica que deja pasar algunos negativos reales clasific√°ndolos como positivos.\n",
    "\n",
    "* Clase 4 (Positivo):\n",
    "Exhibe un patr√≥n opuesto: mayor recall y ligeramente menor precisi√≥n. El modelo identifica correctamente la mayor√≠a de los tweets positivos, aunque comete algunos falsos positivos al confundir tweets negativos como positivos.\n",
    "\n",
    "El balance entre ambas clases es adecuado, con f1-scores muy cercanos (‚âà0.76‚Äì0.79), lo cual confirma que el modelo est√° capturando patrones relevantes del lenguaje en ambas polaridades sin un sesgo fuerte hacia ninguna clase.\n",
    "\n",
    "En t√©rminos generales, el modelo:\n",
    "\n",
    "* Logra un rendimiento competitivo para una tarea cl√°sica de an√°lisis de sentimiento basada en tweets.\n",
    "\n",
    "* Se beneficia del uso de TF-IDF y n-gramas, lo que mejora su capacidad para identificar expresiones contextuales t√≠picas del lenguaje en redes sociales.\n",
    "\n",
    "* Mantiene un comportamiento coherente entre train y test, lo que indica un ajuste apropiado al conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24e4b1",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8494984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78    560000\n",
      "           4       0.78      0.78      0.78    560000\n",
      "\n",
      "    accuracy                           0.78   1120000\n",
      "   macro avg       0.78      0.78      0.78   1120000\n",
      "weighted avg       0.78      0.78      0.78   1120000\n",
      "\n",
      "------------------------------------------------------\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76    240000\n",
      "           4       0.76      0.76      0.76    240000\n",
      "\n",
      "    accuracy                           0.76    480000\n",
      "   macro avg       0.76      0.76      0.76    480000\n",
      "weighted avg       0.76      0.76      0.76    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplico el modelo de regresi√≥n log√≠stica\n",
    "mod_naive_bayes = MultinomialNB()\n",
    "mod_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_nb = mod_naive_bayes.predict(X_train)\n",
    "print(\"Train report:\")\n",
    "print(classification_report(y_train, y_pred_train_nb))\n",
    "print(\"------------------------------------------------------\")\n",
    "y_pred_test_nb = mod_naive_bayes.predict(X_test)\n",
    "print(\"Test report:\")\n",
    "print(classification_report(y_test, y_pred_test_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b854c",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "El modelo de Multinomial Naive Bayes mostr√≥ un rendimiento s√≥lido y estable para la clasificaci√≥n de sentimientos en tweets. Con una accuracy del 78% en entrenamiento y un 76% en la evaluaci√≥n sobre datos de prueba, se observa una diferencia m√≠nima entre ambos conjuntos, lo cual indica que el modelo generaliza bien y no presenta signos significativos de sobreajuste.\n",
    "\n",
    "El comportamiento por clase es notablemente equilibrado:\n",
    "\n",
    "* Clase 0 (Negativo):\n",
    "Tiene valores de precisi√≥n, recall y F1 muy cercanos entre s√≠ (‚âà0.75‚Äì0.78), lo que sugiere que el modelo identifica de forma uniforme tanto los ejemplos negativos como los positivos. No existe una tendencia clara a cometer m√°s falsos positivos o falsos negativos en esta clase.\n",
    "\n",
    "* Clase 4 (Positivo):\n",
    "Presenta pr√°cticamente el mismo rendimiento que la clase negativa, evidenciando que Naive Bayes maneja de manera sim√©trica las caracter√≠sticas ling√º√≠sticas asociadas a ambos polos de sentimiento.\n",
    "\n",
    "Este comportamiento equilibrado se debe a c√≥mo Naive Bayes modela la probabilidad de aparici√≥n de palabras en cada categor√≠a, lo que en un corpus tan grande y balanceado resulta especialmente efectivo. El uso de TF-IDF como representaci√≥n ayuda a capturar mejor la relevancia de los t√©rminos sin generar sobredependencia de palabras extremadamente frecuentes.\n",
    "\n",
    "En t√©rminos generales, el modelo:\n",
    "\n",
    "* Ofrece resultados consistentes y estables.\n",
    "\n",
    "* Es computacionalmente eficiente, lo cual lo hace adecuado para vol√∫menes de datos grandes como este.\n",
    "\n",
    "* Obtiene un rendimiento competitivo y comparable a otros algoritmos m√°s complejos, a pesar de su simplicidad.\n",
    "\n",
    "* Tiende a generar m√©tricas muy balanceadas entre clases, lo cual es una fortaleza cuando el objetivo es la robustez m√°s que la optimizaci√≥n extrema en una clase espec√≠fica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9cf5b4",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e9d1fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train report (XGBoost):\n",
      "0.7271678571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69    560000\n",
      "           1       0.69      0.84      0.75    560000\n",
      "\n",
      "    accuracy                           0.73   1120000\n",
      "   macro avg       0.74      0.73      0.72   1120000\n",
      "weighted avg       0.74      0.73      0.72   1120000\n",
      "\n",
      "------------------------------------------------------\n",
      "Test report (XGBoost):\n",
      "0.72355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.62      0.69    240000\n",
      "           1       0.68      0.83      0.75    240000\n",
      "\n",
      "    accuracy                           0.72    480000\n",
      "   macro avg       0.73      0.72      0.72    480000\n",
      "weighted avg       0.73      0.72      0.72    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Modelo XGBoost para clasificaci√≥n binaria\n",
    "mod_xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    tree_method='hist',   # r√°pido y compatible con matrices grandes\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "y_train_bin = y_train.replace({4:1})\n",
    "y_test_bin = y_test.replace({4:1})\n",
    "\n",
    "# Entrenar\n",
    "mod_xgb.fit(X_train, y_train_bin)\n",
    "\n",
    "# Predicciones train\n",
    "y_pred_train_xgb = mod_xgb.predict(X_train)\n",
    "print(\"Train report (XGBoost):\")\n",
    "print(accuracy_score(y_train_bin, y_pred_train_xgb))\n",
    "print(classification_report(y_train_bin, y_pred_train_xgb))\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "# Predicciones test\n",
    "y_pred_test_xgb = mod_xgb.predict(X_test)\n",
    "print(\"Test report (XGBoost):\")\n",
    "print(accuracy_score(y_test_bin, y_pred_test_xgb))\n",
    "print(classification_report(y_test_bin, y_pred_test_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9dbc0",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "El modelo XGBoost alcanza una accuracy de 73% en entrenamiento y 72% en prueba, mostrando un desempe√±o consistente y equilibrado entre ambos conjuntos. Se observa un recall mayor en la clase positiva (‚âà0.83), mientras que la clase negativa tiene un recall algo menor (‚âà0.62), indicando que el modelo tiende a predecir m√°s correctamente los positivos. En general, XGBoost demuestra ser un clasificador robusto y eficiente para este dataset de tweets, superando en general a modelos m√°s simples y ofreciendo una buena separaci√≥n entre clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6faab1",
   "metadata": {},
   "source": [
    "## Modelo pre-entrenado: Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9f051ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1600000/1600000 [03:56<00:00, 6773.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob accuracy: 0.620114375\n",
      "TextBlob F1 score: 0.6107767810407425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.59      0.78      0.67    800000\n",
      "    Positivo       0.67      0.47      0.55    800000\n",
      "\n",
      "    accuracy                           0.62   1600000\n",
      "   macro avg       0.63      0.62      0.61   1600000\n",
      "weighted avg       0.63      0.62      0.61   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def tb_predict(text):\n",
    "    try:\n",
    "        polarity = TextBlob(text).sentiment.polarity\n",
    "\n",
    "        return 4 if polarity > 0.1 else 0\n",
    "\n",
    "    except Exception:\n",
    "        return 0\n",
    "tb_preds = [tb_predict(t) for t in tqdm(X)]\n",
    "print('TextBlob accuracy:', accuracy_score(y, tb_preds))\n",
    "print('TextBlob F1 score:', f1_score(y, tb_preds, average='macro'))\n",
    "print(classification_report(y, tb_preds, target_names=['Negativo','Positivo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2c0fd",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "El modelo preentrenado TextBlob muestra un rendimiento moderado, alcanzando una accuracy del 62% y un F1 macro de 0.61, valores esperables para un enfoque basado √∫nicamente en reglas l√©xicas. Se observa un mejor desempe√±o identificando tweets negativos (recall 0.78), mientras que presenta mayores dificultades para reconocer los positivos (recall 0.47), reflejando una tendencia a clasificar por defecto hacia la clase negativa. En general, si bien TextBlob ofrece una referencia inicial √∫til, su capacidad predictiva queda claramente por debajo de los modelos entrenados espec√≠ficamente sobre el dataset, reforzando la necesidad de enfoques supervisados para un an√°lisis de sentimiento m√°s preciso. Para esta prueba se quita la opci√≥n de neutros ya que en el dataset que se est√° probando no aparece y haciendo esa quita las estad√≠sticas mejoraron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa57f85",
   "metadata": {},
   "source": [
    "## Similitud coseno entre clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ed473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud coseno entre centroides (Negativo vs Positivo): 0.74377502402738\n"
     ]
    }
   ],
   "source": [
    "X_all = X_train_tfidf\n",
    "y_all = y\n",
    "\n",
    "def promVectorPorclase(X, y, label):\n",
    "    \"\"\"\n",
    "    Calcula el vector TF-IDF promedio para una clase.\n",
    "    X: matriz TF-IDF (sparse)\n",
    "    y: etiquetas (Series o array)\n",
    "    label: clase que quiero (0 o 4)\n",
    "    \"\"\"\n",
    "    mask = (y == label).values        \n",
    "    X_class = X[mask]                 \n",
    "    mean_vec = X_class.mean(axis=0)   \n",
    "    mean_vec = np.asarray(mean_vec).reshape(1, -1)\n",
    "    return mean_vec                   \n",
    "\n",
    "vectorNegativo = promVectorPorclase(X_all, y_all, 0)\n",
    "vectorPositivo = promVectorPorclase(X_all, y_all, 4)\n",
    "similitudNegPos = cosine_similarity(vectorNegativo, vectorPositivo)[0][0]\n",
    "\n",
    "print('Similitud coseno entre centroides (Negativo vs Positivo):', similitudNegPos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b006c2",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "La similitud coseno entre los centroides de ambas clases es 0.744, lo que indica que ambas clases comparten muchos t√©rminos. Aunque no son id√©nticos, su cercan√≠a sugiere que ambas clases comparten una estructura sem√°ntica similar, lo cual explica en parte la dificultad de los modelos para separar completamente los sentimientos. Esto refuerza la importancia de aplicar t√©cnicas adicionales de enriquecimiento sem√°ntico o modelos m√°s complejos si se busca mejorar la discriminaci√≥n entre ambas categor√≠as."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a85f25",
   "metadata": {},
   "source": [
    "### Proceso datos de validaci√≥n\n",
    "\n",
    "Uso el archivo de validaci√≥n utilizando el modelo que mejor perform√≥, el mismo Regresi√≥n log√≠stica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f305891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df_test['polarity'] != 2]\n",
    "X_test_tfidf = tf_idf.transform(df_test['text_clean'])\n",
    "y_val = df_test['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79       177\n",
      "           4       0.80      0.79      0.80       182\n",
      "\n",
      "    accuracy                           0.79       359\n",
      "   macro avg       0.79      0.79      0.79       359\n",
      "weighted avg       0.79      0.79      0.79       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_val = X_test_tfidf\n",
    "y_pred_val = mod_reg_log.predict(x_val)\n",
    "print(\"Validation report:\")\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ec233",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "El modelo de Regresi√≥n Log√≠stica confirma su buen desempe√±o en los datos de validaci√≥n, alcanzando una exactitud del 79% y manteniendo un equilibrio s√≥lido entre precision, recall y f1-score en ambas clases. Estos resultados reflejan una adecuada capacidad de generalizaci√≥n y consolidan al modelo como una soluci√≥n confiable para la clasificaci√≥n de sentimiento en nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f390dc",
   "metadata": {},
   "source": [
    "### Guardo el modelo con mejor performance\n",
    "\n",
    "Dado que el modelo de regresi√≥n logistica es el que tuvo la mejor accuracy, es el seleccionado para ser exportado a un archivo pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a675296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado correctamente en 'Modelo_Sentiment.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar el modelo en un archivo pickle\n",
    "with open(\"./Modelo_Sentiment.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mod_reg_log, f)\n",
    "\n",
    "print(\"Modelo guardado correctamente en 'Modelo_Sentiment.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa51a7d",
   "metadata": {},
   "source": [
    "### Conclusiones finales\n",
    "\n",
    "En este trabajo se evaluaron distintos enfoques para el an√°lisis de sentimiento en tweets:\n",
    "\n",
    "- **Regresi√≥n Log√≠stica** y **Naive Bayes**:  \n",
    "  - Accuracy ‚âà 0.77‚Äì0.79  \n",
    "  - F1 macro ‚âà 0.76‚Äì0.79  \n",
    "  - Observaci√≥n: modelos supervisados eficientes, equilibrados entre clases y capaces de capturar patrones relevantes del lenguaje mediante TF-IDF con n-gramas.\n",
    "\n",
    "- **XGBoost**:  \n",
    "  - Accuracy ‚âà 0.72‚Äì0.73  \n",
    "  - F1 macro ‚âà 0.72  \n",
    "  - Observaci√≥n: modelo robusto y estable; ligeramente mejor predicci√≥n de la clase positiva, mostrando consistencia entre entrenamiento y prueba.\n",
    "\n",
    "- **TextBlob (preentrenado)**:  \n",
    "  - Accuracy ‚âà 0.62  \n",
    "  - F1 macro ‚âà 0.61  \n",
    "  - Observaci√≥n: √∫til como referencia inicial, pero limitado para separar las clases de manera efectiva.\n",
    "\n",
    "**Interpretaci√≥n general:**  \n",
    "La similitud coseno entre centroides (‚âà0.74) indica que los tweets negativos y positivos comparten patrones ling√º√≠sticos cercanos, lo que explica la dificultad de lograr clasificaci√≥n perfecta. Los modelos supervisados entrenados sobre el dataset espec√≠fico superan claramente a TextBlob, demostrando la importancia del entrenamiento con datos reales.  \n",
    "\n",
    "**Conclusi√≥n final:**  \n",
    "Los modelos supervisados basados en TF-IDF representan la opci√≥n m√°s efectiva para clasificar sentimientos en tweets, mientras que los m√©todos basados en reglas pueden servir como l√≠nea base o referencia. La combinaci√≥n de m√©tricas de desempe√±o y an√°lisis de similitud sem√°ntica permite comprender tanto las fortalezas como las limitaciones de cada enfoque.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
